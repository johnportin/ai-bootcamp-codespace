{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02578408",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fd5cbb-a06f-431f-a559-019f99439d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23870f3a-9c3e-460e-916b-5df55c9213e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt, instructions=None, model='gpt-4o-mini'):\n",
    "    messages = []\n",
    "\n",
    "    if instructions:\n",
    "        messages.append({\n",
    "            'role': 'system',\n",
    "            'content': instructions\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        'role': 'user',\n",
    "        'content': user_prompt\n",
    "    })\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e6a9915-b98c-433f-a9ca-f096da17b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'what is the objective of the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24ae3fcc-ca87-4713-97d8-d684c5fb4716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To provide an accurate response, I would need some context about the specific course you're referring to. Generally, the objectives of a course can include:\\n\\n1. **Knowledge Acquisition**: To help students gain a deep understanding of the subject matter.\\n2. **Skill Development**: To equip students with practical skills relevant to the field.\\n3. **Critical Thinking**: To encourage analytical thinking and problem-solving skills.\\n4. **Application of Knowledge**: To enable students to apply what they’ve learned in real-world situations.\\n5. **Collaboration and Communication**: To promote teamwork and effective communication skills.\\n6. **Assessment and Reflection**: To engage students in evaluating their understanding and progress.\\n\\nIf you provide the subject or name of the course, I can give you a more detailed objective.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d1f68f2-59fe-4975-83f3-c50a95ce1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd993b54-4345-4531-8d14-00a5cbd384ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7965ecfe39e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import Index\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fd346e-4d62-4533-b026-aef6f00aba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp'}\n",
      "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus', 'section': 'General course-related questions', 'question': 'I just joined. What should I do next? How can I access course materials?', 'course': 'machine-learning-zoomcamp'}\n",
      "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "question = 'I just found the course. Can I join now?'\n",
    "\n",
    "results = index.search(\n",
    "    question,\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11b03429-4937-4896-bc71-7b6165b6594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9880470e-810c-4ff7-9419-0008e6d8d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(question, search_results):\n",
    "    search_json = json.dumps(search_results)\n",
    "    return prompt_template.format(\n",
    "        question=question,\n",
    "        context=search_json\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1626f51-3b5b-490c-a766-779201805eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    print(prompt)\n",
    "    answer = llm(prompt, instructions=instructions)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d1f995d-2926-4a43-a642-fe9e3a95eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QUESTION>\n",
      "how do I install Kafka in Python?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "[{\"text\": \"confluent-kafka: `pip install confluent-kafka` or `conda install conda-forge::python-confluent-kafka`\\nfastavro: pip install fastavro\\nAbhirup Ghosh\\nCan install Faust Library for Module 6 Python Version due to dependency conflicts?\\nThe Faust repository and library is no longer maintained - https://github.com/robinhood/faust\\nIf you do not know Java, you now have the option to follow the Python Videos 6.13 & 6.14 here https://www.youtube.com/watch?v=BgAlVknDFlQ&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=80  and follow the RedPanda Python version here https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/06-streaming/python/redpanda_example - NOTE: I highly recommend watching the Java videos to understand the concept of streaming but you can skip the coding parts - all will become clear when you get to the Python videos and RedPanda files.\", \"section\": \"Module 6: streaming with kafka\", \"question\": \"Python Kafka: Installing dependencies for python3 06-streaming/python/avro_example/producer.py\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"Run this command in terminal in the same directory (/docker/spark):\\nchmod +x build.sh\", \"section\": \"Module 6: streaming with kafka\", \"question\": \"Python Kafka: ./build.sh: Permission denied Error\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"A generator is a function in python that returns an iterator using the yield keyword.\\nA generator is a special type of iterable, similar to a list or a tuple, but with a crucial difference. Instead of creating and storing all the values in memory at once, a generator generates values on-the-fly as you iterate over it. This makes generators memory-efficient, particularly when dealing with large datasets.\", \"section\": \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\", \"question\": \"Python - Generators in python\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you\\u2019re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\", \"section\": \"Workshop 1 - dlthub\", \"question\": \"How do I install the necessary dependencies to run the code?\", \"course\": \"data-engineering-zoomcamp\"}, {\"text\": \"Python 3.12.1, is not compatible with kafka-python-2.0.2. Therefore, instead of running \\\"pip install kafka-python\\\", you can resolve the issue by using \\\"pip install git+https://github.com/dpkp/kafka-python.git\\\". If you have already installed kafka-python, you need to run \\\"pip uninstall kafka-python\\\" before executing \\\"pip install git+https://github.com/dpkp/kafka-python.git\\\" to resolve the compatibility issue.\\nQ:In the Mage pipeline, individual blocks run successfully. However, when executing the pipeline as a whole, some blocks fail.\\nA: I have the following key-value pair in io_config.yaml file configured but still Mage blocks failed to generate OAuth and authenticate with GCP: GOOGLE_SERVICE_ACC_KEY_FILEPATH: \\\"{{ env_var('GCP_CREDENTIALS') }}\\\". The GCP_CREDENTIALS variable holds the full path to the service account key's JSON file. Adding the following line within the failed code block resolved the issue: os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.environ.get('GCP_CREDENTIALS').\\nThis occurs because the path to profiles.yml is not correctly specified. You can rectify this by:\\n\\u201cexport DBT_PROFILES_DBT=path/to/profiles.yml\\u201d\\nEg., /home/src/magic-zoomcamp/dbt/project_name/\\nDo the similar for DBT_PROJECT_DIR if getting similar issue with dbt_project.yml.\\nOnce DIRs are set,:\\n\\u201cdbt debug \\u2013config-dir\\u201d\\nThis would update your paths. To maintain same path across sessions, use the path variables in your .env file.\\nTo add triggers in mage pipelines via CLI, you can create a trigger of type API, and copy the API links.\\nEg. link: http://localhost:6789/api/pipeline_schedules/10/pipeline_runs/f3a1a4228fc64cfd85295b668c93f3b2\\nThen create a trigger.py as such:\\nimport os\\nimport requests\\nclass MageTrigger:\\nOPTIONS = {\\n\\\"<pipeline_name>\\\": {\\n\\\"trigger_id\\\": 10,\\n\\\"key\\\": \\\"f3a1a4228fc64cfd85295b668c93f3b2\\\"\\n}\\n}\\n@staticmethod\\ndef trigger_pipeline(pipeline_name, variables=None):\\ntrigger_id = MageTrigger.OPTIONS[pipeline_name][\\\"trigger_id\\\"]\\nkey = MageTrigger.OPTIONS[pipeline_name][\\\"key\\\"]\\nendpoint = f\\\"http://localhost:6789/api/pipeline_schedules/{trigger_id}/pipeline_runs/{key}\\\"\\nheaders = {'Content-Type': 'application/json'}\\npayload = {}\\nif variables is not None:\\npayload['pipeline_run'] = {'variables': variables}\\nresponse = requests.post(endpoint, headers=headers, json=payload)\\nreturn response\\nMageTrigger.trigger_pipeline(\\\"<pipeline_name>\\\")\\nFinally, after the mage server is up an running, simply this command:\\npython trigger.py from mage directory in terminal.\\nCan I do data partitioning & clustering run by dbt pipeline, or I would need to do this manually in BigQuery afterwards?\\nYou can use this configuration in your DBT model:\\n{\\n\\\"field\\\": \\\"<field name>\\\",\\n\\\"data_type\\\": \\\"<timestamp | date | datetime | int64>\\\",\\n\\\"granularity\\\": \\\"<hour | day | month | year>\\\"\\n# Only required if data_type is \\\"int64\\\"\\n\\\"range\\\": {\\n\\\"start\\\": <int>,\\n\\\"end\\\": <int>,\\n\\\"interval\\\": <int>\\n}\\n}\\nand for clustering\\n{{\\nconfig(\\nmaterialized = \\\"table\\\",\\ncluster_by = \\\"order_id\\\",\\n)\\n}}\\nmore details in: https://docs.getdbt.com/reference/resource-configs/bigquery-configs\", \"section\": \"Triggers in Mage via CLI\", \"question\": \"Encountering the error \\\"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\\\" when running \\\"from kafka import KafkaProducer\\\" in Jupyter Notebook for Module 6 Homework?\", \"course\": \"data-engineering-zoomcamp\"}]\n",
      "</CONTEXT>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To install Kafka in Python, you can use the following commands:\\n\\n1. Install the Confluent Kafka client:\\n   ```bash\\n   pip install confluent-kafka\\n   ```\\n   or if you're using conda:\\n   ```bash\\n   conda install conda-forge::python-confluent-kafka\\n   ```\\n\\n2. If needed, also install `fastavro`:\\n   ```bash\\n   pip install fastavro\\n   ```\\n\\nIf you encounter compatibility issues, especially with specific versions of Python, consider using:\\n```bash\\npip uninstall kafka-python\\npip install git+https://github.com/dpkp/kafka-python.git\\n``` \\n\\nMake sure you adapt the installation commands based on your environment and requirements.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I install Kafka in Python?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
